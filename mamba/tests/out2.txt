load finish!
====state====
inference_params.prev_memory_list: 1
inference_params.prev_memory_list: 2
inference_params.prev_memory_list: 3
inference_params.prev_memory_list: 4
inference_params.prev_memory_list: 5
inference_params.prev_memory_list: 6
inference_params.prev_memory_list: 7
inference_params.prev_memory_list: 8
inference_params.prev_memory_list: 9
inference_params.prev_memory_list: 10
draft model text: 
June 1st.  Having taken our leaves of Sir W. Batten and my Lady, who are
gone this morning to keep their Whitsuntide, Sir W. Pen and I and Mr.
Gauden by water to Woolwich, and there went from ship to ship to give
order for and take notice of their forwardness to go forth, and then to
Deptford and did the like, having dined at Woolwich with Captain Poole at
the tavern there.  From Deptford we walked to Redriffe, calling at the
half-way house, and there come into a room where there was infinite of new
cakes placed that are made against Whitsuntide, and there we were very
merry.  By water home, and there did businesses of the office. Among
others got my Lord's imprest of L1000 and Mr. Creed's of L10,000 against
this voyage their bills signed.  Having wrote letters into the country and
read some things I went to bed.

2nd.  Up and to my office, where 
ranks: tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')
is_mismatch, mismatch_position: tensor([False], device='cuda:0') tensor([838], device='cuda:0')
inference_params.prev_memory_list: 1
inference_params.prev_memory_list: 2
inference_params.prev_memory_list: 3
inference_params.prev_memory_list: 4
inference_params.prev_memory_list: 5
inference_params.prev_memory_list: 6
inference_params.prev_memory_list: 7
inference_params.prev_memory_list: 8
inference_params.prev_memory_list: 9
inference_params.prev_memory_list: 10
draft model text: I did give my Lord an account of the

ranks: tensor([[ 0,  5,  1,  0,  0, 12,  2,  0,  0,  0,  5,  0,  0, 18,  0,  0,  0,  0,
          0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,
          0]], device='cuda:0')
is_mismatch, mismatch_position: tensor([True], device='cuda:0') tensor([1], device='cuda:0')
verifier_matched_tokens: tensor([73, 32], device='cuda:0')
tensor([[73, 32]], device='cuda:0')
restart_token: tensor([[ 32, 104]], device='cuda:0') mismatch_token: tensor([104], device='cuda:0')
unprocess_tokens: [tensor([104], device='cuda:0')]
unprocess_tokens until space: [tensor([104], device='cuda:0'), tensor([101], device='cuda:0'), tensor([32], device='cuda:0')]
match_text: I 
match_draft_tokens: tensor([[11]], device='cuda:0')
unprocess_text: he 
inference_params.prev_memory_list: 11
inference_params.prev_memory_list: 1
inference_params.prev_memory_list: 2
inference_params.prev_memory_list: 3
inference_params.prev_memory_list: 4
inference_params.prev_memory_list: 5
inference_params.prev_memory_list: 6
inference_params.prev_memory_list: 7
inference_params.prev_memory_list: 8
inference_params.prev_memory_list: 9
inference_params.prev_memory_list: 10
draft model text: did give me an account of the
business of 
ranks: tensor([[ 2,  2,  0, 17,  2,  0,  0,  0,  2,  0,  0,  0,  1,  0,  1,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0, 11,  1,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0]], device='cuda:0')
is_mismatch, mismatch_position: tensor([True], device='cuda:0') tensor([3], device='cuda:0')
verifier_matched_tokens: tensor([100, 105, 100,  32], device='cuda:0')
tensor([[100, 105, 100,  32]], device='cuda:0')
restart_token: tensor([[ 32, 115,  32, 110]], device='cuda:0') mismatch_token: tensor([110], device='cuda:0')
unprocess_tokens: [tensor([110], device='cuda:0')]
unprocess_tokens until space: [tensor([110], device='cuda:0'), tensor([32], device='cuda:0')]
match_text: did 
match_draft_tokens: tensor([[134]], device='cuda:0')
unprocess_text: n 
inference_params.prev_memory_list: 11
inference_params.prev_memory_list: 1
inference_params.prev_memory_list: 2
inference_params.prev_memory_list: 3
inference_params.prev_memory_list: 4
inference_params.prev_memory_list: 5
inference_params.prev_memory_list: 6
inference_params.prev_memory_list: 7
inference_params.prev_memory_list: 8
inference_params.prev_memory_list: 9
inference_params.prev_memory_list: 10
draft model text: mind my being called to
the office to answer 
ranks: tensor([[ 4,  0,  1,  0,  6,  3,  0,  1,  2,  0,  0,  0,  0,  6,  0,  0,  0,  0,
          0,  0,  1,  0,  1,  0,  0,  0,  0,  0, 18,  0,  0,  0,  0,  0,  0,  1,
          0,  0,  0,  0,  0,  0,  0,  0,  0]], device='cuda:0')
is_mismatch, mismatch_position: tensor([True], device='cuda:0') tensor([0], device='cuda:0')
verifier_matched_tokens: tensor([109], device='cuda:0')
tensor([[109]], device='cuda:0')
restart_token: tensor([[101]], device='cuda:0') mismatch_token: tensor([101], device='cuda:0')
unprocess_tokens: [tensor([101], device='cuda:0')]
unprocess_tokens until space: [tensor([101], device='cuda:0'), tensor([32], device='cuda:0')]
match_text: m
match_draft_tokens: tensor([[31935]], device='cuda:0')
unprocess_text: e 
inference_params.prev_memory_list: 11
inference_params.prev_memory_list: 1
inference_params.prev_memory_list: 2
inference_params.prev_memory_list: 3
inference_params.prev_memory_list: 4
inference_params.prev_memory_list: 5
inference_params.prev_memory_list: 6
inference_params.prev_memory_list: 7
inference_params.prev_memory_list: 8
inference_params.prev_memory_list: 9
inference_params.prev_memory_list: 10
draft model text: the office to
have a meeting of Tangie
ranks: tensor([[ 0,  0,  0, 11,  5,  0,  0,  0,  0,  1,  3,  0,  1,  0,  6,  1,  0,  0,
          0,  1,  0,  8,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0, 26,  2,  3,  1,
          0,  0]], device='cuda:0')
is_mismatch, mismatch_position: tensor([True], device='cuda:0') tensor([3], device='cuda:0')
verifier_matched_tokens: tensor([116, 104, 101,  32], device='cuda:0')
tensor([[116, 104, 101,  32]], device='cuda:0')
restart_token: tensor([[104, 101,  32, 115]], device='cuda:0') mismatch_token: tensor([115], device='cuda:0')
unprocess_tokens: [tensor([115], device='cuda:0')]
unprocess_tokens until space: [tensor([115], device='cuda:0'), tensor([32], device='cuda:0')]
match_text: the 
match_draft_tokens: tensor([[2]], device='cuda:0')
unprocess_text: s 
inference_params.prev_memory_list: 11
inference_params.prev_memory_list: 1
inference_params.prev_memory_list: 2
inference_params.prev_memory_list: 3
inference_params.prev_memory_list: 4
inference_params.prev_memory_list: 5
inference_params.prev_memory_list: 6
inference_params.prev_memory_list: 7
inference_params.prev_memory_list: 8
inference_params.prev_memory_list: 9
inference_params.prev_memory_list: 10
draft model text: and did
agree with him to go to the 
ranks: tensor([[ 0,  0,  0, 11,  1,  1,  1,  0,  4, 11,  1,  0,  0,  0,  1,  0,  0,  0,
          0,  1,  0,  0,  0,  0,  1,  0,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0]],
       device='cuda:0')
is_mismatch, mismatch_position: tensor([True], device='cuda:0') tensor([3], device='cuda:0')
verifier_matched_tokens: tensor([ 97, 110, 100,  32], device='cuda:0')
tensor([[ 97, 110, 100,  32]], device='cuda:0')
restart_token: tensor([[110, 100,  32, 116]], device='cuda:0') mismatch_token: tensor([116], device='cuda:0')
unprocess_tokens: [tensor([116], device='cuda:0')]
unprocess_tokens until space: [tensor([116], device='cuda:0'), tensor([104], device='cuda:0'), tensor([101], device='cuda:0'), tensor([32], device='cuda:0')]
match_text: and 
match_draft_tokens: tensor([[4]], device='cuda:0')
unprocess_text: the 
inference_params.prev_memory_list: 11
inference_params.prev_memory_list: 1
inference_params.prev_memory_list: 2
inference_params.prev_memory_list: 3
inference_params.prev_memory_list: 4
inference_params.prev_memory_list: 5
inference_params.prev_memory_list: 6
inference_params.prev_memory_list: 7
inference_params.prev_memory_list: 8
inference_params.prev_memory_list: 9
inference_params.prev_memory_list: 10
draft model text: s
e e e e e e e e 
ranks: tensor([[ 9,  0, 14, 26, 14,  1, 13,  0,  8,  0,  1,  0,  0,  0,  0,  0,  0,  0]],
       device='cuda:0')
is_mismatch, mismatch_position: tensor([True], device='cuda:0') tensor([0], device='cuda:0')
verifier_matched_tokens: tensor([115], device='cuda:0')
tensor([[115]], device='cuda:0')
restart_token: tensor([[32]], device='cuda:0') mismatch_token: tensor([32], device='cuda:0')
unprocess_tokens: [tensor([32], device='cuda:0')]
unprocess_tokens until space: [tensor([32], device='cuda:0')]
match_text: s
match_draft_tokens: tensor([[31941]], device='cuda:0')
unprocess_text:  
inference_params.prev_memory_list: 11
inference_params.prev_memory_list: 1
inference_params.prev_memory_list: 2
inference_params.prev_memory_list: 3
inference_params.prev_memory_list: 4
inference_params.prev_memory_list: 5
inference_params.prev_memory_list: 6
inference_params.prev_memory_list: 7
inference_params.prev_memory_list: 8
inference_params.prev_memory_list: 9
inference_params.prev_memory_list: 10
draft model text: :
and did it all the morning and did 
ranks: tensor([[ 1,  0,  4,  0,  0,  0, 17,  2,  0,  0,  5,  0,  0,  4,  0,  0,  0,  2,
          0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  3,  0,  0,
          0]], device='cuda:0')
is_mismatch, mismatch_position: tensor([True], device='cuda:0') tensor([2], device='cuda:0')
verifier_matched_tokens: tensor([58, 13, 10], device='cuda:0')
tensor([[58, 13, 10]], device='cuda:0')
restart_token: tensor([[32, 10, 13]], device='cuda:0') mismatch_token: tensor([13], device='cuda:0')
unprocess_tokens: [tensor([13], device='cuda:0')]
unprocess_tokens until space: [tensor([13], device='cuda:0'), tensor([10], device='cuda:0')]
match_text: :

match_draft_tokens: tensor([[29598, 31836]], device='cuda:0')
unprocess_text: 

inference_params.prev_memory_list: 11
inference_params.prev_memory_list: 1
inference_params.prev_memory_list: 2
inference_params.prev_memory_list: 3
inference_params.prev_memory_list: 4
inference_params.prev_memory_list: 5
inference_params.prev_memory_list: 6
inference_params.prev_memory_list: 7
inference_params.prev_memory_list: 8
inference_params.prev_memory_list: 9
inference_params.prev_memory_list: 10
draft model text: 3rd.  To White Hall, where I did 
ranks: tensor([[20,  0,  2,  0,  1,  1,  1,  0,  7,  2,  0,  0,  0,  1,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  7,  0,  0,  0]],
       device='cuda:0')
is_mismatch, mismatch_position: tensor([True], device='cuda:0') tensor([0], device='cuda:0')
verifier_matched_tokens: tensor([51], device='cuda:0')
tensor([[51]], device='cuda:0')
restart_token: tensor([[48]], device='cuda:0') mismatch_token: tensor([48], device='cuda:0')
unprocess_tokens: [tensor([48], device='cuda:0')]
